{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import webbrowser\n",
    "import os\n",
    "import math\n",
    "\n",
    "from h3 import h3\n",
    "from folium import Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    column_types = {'Accident_Index': np.string_, 'LSOA_of_Accident_Location': np.string_}\n",
    "    uk2015 = pd.read_csv(\"data/DfTRoadSafety_Accidents_2015.csv\", dtype=column_types)\n",
    "    uk2016 = pd.read_csv(\"data/dftRoadSafety_Accidents_2016.csv\", dtype=column_types)\n",
    "    return uk2015.append(uk2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_map` function creates and populates a folium map from the given `clusters` dictionary. Each value of the dictionary is also a dictionary with two recognizable keys: `geom` and `count`. The value associated with the `geom` key is the list of locations of the hexagon's vertices. The value associated with the `count` key contains the number of accidents counted within this shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(clusters):\n",
    "    # Create the map object\n",
    "    map = Map(tiles=\"cartodbpositron\", \n",
    "          attr= '© <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors © <a href=\"http://cartodb.com/attributions#basemaps\">CartoDB</a>')\n",
    "\n",
    "    # Convert the clusters dictionary items to polygons and add them to the map\n",
    "    for cluster in clusters.values():\n",
    "        points = cluster['geom'][0]\n",
    "        points = [p[::-1] for p in points]\n",
    "        tooltip = \"{0} accidents\".format(cluster['count'])\n",
    "        polygon = folium.vector_layers.Polygon(locations=points, tooltip=tooltip,\n",
    "                                               fill=True, \n",
    "                                               color='#ff0000', \n",
    "                                               fill_color='#ff0000', \n",
    "                                               fill_opacity=0.4, weight=3, opacity=0.4)\n",
    "        polygon.add_to(map)\n",
    "\n",
    "    # Determine the map bounding box\n",
    "    max_lat = df.Latitude.max()\n",
    "    min_lat = df.Latitude.min()\n",
    "    max_lon = df.Longitude.max()\n",
    "    min_lon = df.Longitude.min()\n",
    "    \n",
    "    # Fit the map to the bounds\n",
    "    map.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]])\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show_map` function saves the HTML generated by the map into a file and then opens a new browser tab with its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_map(map, file_name):\n",
    "    map.save(file_name)\n",
    "    wb = webbrowser.open('file://' + os.path.realpath(file_name), new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Cleaning\n",
    "Start by loading the data files for 2015 and 2016. Please note that more data files are available on the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_acc = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_acc.dropna()\n",
    "\n",
    "uk_acc = uk_acc.loc[uk_acc.Latitude <=  90.0]\n",
    "uk_acc = uk_acc.loc[uk_acc.Latitude >= -90.0]\n",
    "\n",
    "uk_acc = uk_acc.loc[uk_acc.Longitude <=  180.0]\n",
    "uk_acc = uk_acc.loc[uk_acc.Longitude >= -180.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the radian longitude and latitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_acc['rad_lng'] = np.radians(uk_acc['Longitude'].to_numpy())\n",
    "uk_acc['rad_lat'] = np.radians(uk_acc['Latitude'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_in_meters = 50.0\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "earth_perimeter = 40070000.0  # In meters\n",
    "eps_in_radians = eps_in_meters / earth_perimeter * (2 * math.pi)\n",
    "\n",
    "uk_acc['cluster'] = DBSCAN(eps=eps_in_radians, min_samples=num_samples, metric='haversine').fit_predict(uk_acc[['rad_lat', 'rad_lng']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the detail level for the H3 tiles. See the official table [here](https://uber.github.io/h3/#/documentation/core-library/resolution-table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `lat_lng_to_h3` converts a location's coordinates into an H3 key of the preset level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lng_to_h3(row):\n",
    "    return h3.geo_to_h3(row['Latitude'], row['Longitude'], h3_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame column with the H3 encoded key for the given latitude and longitude pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_acc['h3'] = uk_acc.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the locations that belong to a DBSCAN-generated cluster. Clusters marked with -1 are noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = uk_acc[uk_acc.cluster != -1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the cluster dictionary. Note that we are just collecting the locations that belong in a cluster, _irrespective of the cluster_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dict()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    key = row['h3']\n",
    "    if key in clusters:\n",
    "        clusters[key]['count'] += 1\n",
    "    else:\n",
    "        clusters[key] = {\"count\": 1,\n",
    "                         \"geom\": [h3.h3_to_geo_boundary(h3_address=key, geo_json=True)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and show the map from the clusters created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = create_map(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_map(map, \"map_{0}.html\".format(h3_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with H3\n",
    "Clustering with H3 is easy. Just iterate through all points and aggregate the hit counts for each key. Here we don't care about noise, all points are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_clusters = dict()\n",
    "\n",
    "for index, row in uk_acc.iterrows():\n",
    "    key = row['h3']\n",
    "    if key in h3_clusters:\n",
    "        h3_clusters[key][\"count\"] += 1\n",
    "    else:\n",
    "        h3_clusters[key] = {\"count\": 1,\n",
    "                            \"geom\": [h3.h3_to_geo_boundary(h3_address=key, geo_json=True)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only be displaying clusters with at least five observations (an arbitrary number, of course). Restricting the minimum count helps limit the number of hexagons that are displayed, which might have an impact on the map performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_clusters = { key:value for (key,value) in h3_clusters.items() if value['count'] >= 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We can now show the map with the H3-generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_map = create_map(relevant_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_map(h3_map, \"map_h3_{0}.html\".format(h3_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KeplerGl to Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    }
   ],
   "source": [
    "kg = KeplerGl(height=400, data={\"accidents\": uk_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
